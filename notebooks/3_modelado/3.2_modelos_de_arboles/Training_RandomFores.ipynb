{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de Árboles de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descripción\n",
    "\n",
    "Random Forest es un modelo de aprendizaje supervisado basado en árboles de decisión que emplea el principio de ensamble para mejorar la precisión y la robustez de las predicciones. Este enfoque se utiliza principalmente en datos tabulares y es una de las técnicas más populares y eficientes en tareas de clasificación y regresión.\n",
    "\n",
    "Además, este modelo pertenece a la categoría de modelos de tipo bagging  ya que emplea una combinación de múltiples árboles de decisión entrenados de manera independiente y al final se elige la solución mayoritaria o el promedio de las predicciones. Por lo que Random Forest al permitir emplear múltiples árboles de decisión entrenados de distinta manera, permitiendo reducir el sobreajuste y mejorar la generalización. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este proyecto vamos a emplear el primer preprocesado realizado, a continuación se llevará a cabo la técnica de submuestreo para balancear el conjunto de los datos. Pese a que se haya probado otra técnica como SMOTE para balancear los datos, pese a que no porporcionaba buenas métricas, se ha decantado por el uso del submuestreo. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>LoanNr_ChkDgt</th>\n",
       "      <th>Name</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Bank</th>\n",
       "      <th>BankState</th>\n",
       "      <th>ApprovalDate</th>\n",
       "      <th>ApprovalFY</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>...</th>\n",
       "      <th>CreateJob</th>\n",
       "      <th>RetainedJob</th>\n",
       "      <th>FranchiseCode</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>LowDoc</th>\n",
       "      <th>DisbursementDate</th>\n",
       "      <th>DisbursementGross</th>\n",
       "      <th>BalanceGross</th>\n",
       "      <th>Accept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bd9d6267ec5</td>\n",
       "      <td>1523195006</td>\n",
       "      <td>P-SCAPE LAND DESIGN, LLC</td>\n",
       "      <td>NORTHFIELD</td>\n",
       "      <td>OH</td>\n",
       "      <td>CITIZENS BANK NATL ASSOC</td>\n",
       "      <td>RI</td>\n",
       "      <td>2005-11-01</td>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2005-12-31</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9eebf6d8098</td>\n",
       "      <td>1326365010</td>\n",
       "      <td>The Fresh &amp; Healthy Catering C</td>\n",
       "      <td>CANTON</td>\n",
       "      <td>OH</td>\n",
       "      <td>FIRSTMERIT BANK, N.A.</td>\n",
       "      <td>OH</td>\n",
       "      <td>2005-06-06</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2005-07-31</td>\n",
       "      <td>166000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83806858500</td>\n",
       "      <td>6179584001</td>\n",
       "      <td>AARON MASON &amp; HOWE LLC</td>\n",
       "      <td>SAWYERWOOD</td>\n",
       "      <td>OH</td>\n",
       "      <td>PNC BANK, NATIONAL ASSOCIATION</td>\n",
       "      <td>OH</td>\n",
       "      <td>2003-03-18</td>\n",
       "      <td>2003</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2003-03-31</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a21ab9cb3af</td>\n",
       "      <td>8463493009</td>\n",
       "      <td>MID OHIO CAR WASH</td>\n",
       "      <td>COLUMBUS</td>\n",
       "      <td>OH</td>\n",
       "      <td>THE HUNTINGTON NATIONAL BANK</td>\n",
       "      <td>OH</td>\n",
       "      <td>1995-06-28</td>\n",
       "      <td>1995</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1996-01-31</td>\n",
       "      <td>220100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>883b5e5385e</td>\n",
       "      <td>3382225007</td>\n",
       "      <td>Bake N Brew LLC</td>\n",
       "      <td>Newark</td>\n",
       "      <td>OH</td>\n",
       "      <td>THE HUNTINGTON NATIONAL BANK</td>\n",
       "      <td>OH</td>\n",
       "      <td>2009-04-16</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009-05-31</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22830</th>\n",
       "      <td>4f9443d2a46</td>\n",
       "      <td>1573725008</td>\n",
       "      <td>SIBILA RACE ENGINEERING, INC</td>\n",
       "      <td>MASSILLON</td>\n",
       "      <td>OH</td>\n",
       "      <td>CITIZENS BANK NATL ASSOC</td>\n",
       "      <td>RI</td>\n",
       "      <td>2005-12-09</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2005-12-31</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22831</th>\n",
       "      <td>798db2753a7</td>\n",
       "      <td>2011184008</td>\n",
       "      <td>ENVIRO SHIELD POWER WASHING</td>\n",
       "      <td>SPRINGBORO</td>\n",
       "      <td>OH</td>\n",
       "      <td>PNC BANK, NATIONAL ASSOCIATION</td>\n",
       "      <td>OH</td>\n",
       "      <td>1998-04-27</td>\n",
       "      <td>1998</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1998-05-31</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22832</th>\n",
       "      <td>ddb3c5e9bff</td>\n",
       "      <td>4082983001</td>\n",
       "      <td>MAINLINE TRCK&amp;TRAILR SRVC, INC</td>\n",
       "      <td>BEDFORD</td>\n",
       "      <td>OH</td>\n",
       "      <td>GROWTH CAPITAL CORP.</td>\n",
       "      <td>OH</td>\n",
       "      <td>1990-05-09</td>\n",
       "      <td>1990</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1991-02-13</td>\n",
       "      <td>92000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22833</th>\n",
       "      <td>407200a5dfe</td>\n",
       "      <td>7783283010</td>\n",
       "      <td>TIN BOX STUDIO</td>\n",
       "      <td>CINCINNATI</td>\n",
       "      <td>OH</td>\n",
       "      <td>KEYBANK NATIONAL ASSOCIATION</td>\n",
       "      <td>OH</td>\n",
       "      <td>1994-11-10</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1995-01-31</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22834</th>\n",
       "      <td>eaa66193392</td>\n",
       "      <td>1513375008</td>\n",
       "      <td>Lowex, Inc.</td>\n",
       "      <td>Dayton</td>\n",
       "      <td>OH</td>\n",
       "      <td>BUSINESS LOAN CENTER, LLC</td>\n",
       "      <td>FL</td>\n",
       "      <td>2005-10-25</td>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2005-11-30</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22835 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  LoanNr_ChkDgt                            Name        City  \\\n",
       "0      bd9d6267ec5     1523195006        P-SCAPE LAND DESIGN, LLC  NORTHFIELD   \n",
       "1      9eebf6d8098     1326365010  The Fresh & Healthy Catering C      CANTON   \n",
       "2      83806858500     6179584001          AARON MASON & HOWE LLC  SAWYERWOOD   \n",
       "3      a21ab9cb3af     8463493009               MID OHIO CAR WASH    COLUMBUS   \n",
       "4      883b5e5385e     3382225007                 Bake N Brew LLC      Newark   \n",
       "...            ...            ...                             ...         ...   \n",
       "22830  4f9443d2a46     1573725008    SIBILA RACE ENGINEERING, INC   MASSILLON   \n",
       "22831  798db2753a7     2011184008     ENVIRO SHIELD POWER WASHING  SPRINGBORO   \n",
       "22832  ddb3c5e9bff     4082983001  MAINLINE TRCK&TRAILR SRVC, INC     BEDFORD   \n",
       "22833  407200a5dfe     7783283010                  TIN BOX STUDIO  CINCINNATI   \n",
       "22834  eaa66193392     1513375008                     Lowex, Inc.      Dayton   \n",
       "\n",
       "      State                            Bank BankState ApprovalDate  \\\n",
       "0        OH        CITIZENS BANK NATL ASSOC        RI   2005-11-01   \n",
       "1        OH           FIRSTMERIT BANK, N.A.        OH   2005-06-06   \n",
       "2        OH  PNC BANK, NATIONAL ASSOCIATION        OH   2003-03-18   \n",
       "3        OH    THE HUNTINGTON NATIONAL BANK        OH   1995-06-28   \n",
       "4        OH    THE HUNTINGTON NATIONAL BANK        OH   2009-04-16   \n",
       "...     ...                             ...       ...          ...   \n",
       "22830    OH        CITIZENS BANK NATL ASSOC        RI   2005-12-09   \n",
       "22831    OH  PNC BANK, NATIONAL ASSOCIATION        OH   1998-04-27   \n",
       "22832    OH            GROWTH CAPITAL CORP.        OH   1990-05-09   \n",
       "22833    OH    KEYBANK NATIONAL ASSOCIATION        OH   1994-11-10   \n",
       "22834    OH       BUSINESS LOAN CENTER, LLC        FL   2005-10-25   \n",
       "\n",
       "       ApprovalFY  NoEmp  ...  CreateJob  RetainedJob  FranchiseCode  \\\n",
       "0            2006      2  ...          0            2              0   \n",
       "1            2005      2  ...          1            2              1   \n",
       "2            2003      2  ...          4            2              1   \n",
       "3            1995      2  ...          0            0              1   \n",
       "4            2009      0  ...          0            0              0   \n",
       "...           ...    ...  ...        ...          ...            ...   \n",
       "22830        2006      1  ...          0            1              0   \n",
       "22831        1998      2  ...          0            0              1   \n",
       "22832        1990     16  ...          6           10              1   \n",
       "22833        1995      1  ...          0            0              1   \n",
       "22834        2006      2  ...          1            2              0   \n",
       "\n",
       "       UrbanRural  RevLineCr  LowDoc  DisbursementDate DisbursementGross  \\\n",
       "0               1        0.0     0.0        2005-12-31            8000.0   \n",
       "1               1        0.0     0.0        2005-07-31          166000.0   \n",
       "2               2        1.0     0.0        2003-03-31           25000.0   \n",
       "3               0        0.0     0.0        1996-01-31          220100.0   \n",
       "4               1        0.0     0.0        2009-05-31           25000.0   \n",
       "...           ...        ...     ...               ...               ...   \n",
       "22830           1        0.0     0.0        2005-12-31           70000.0   \n",
       "22831           0        0.0     1.0        1998-05-31           30000.0   \n",
       "22832           0        0.0     0.0        1991-02-13           92000.0   \n",
       "22833           0        0.0     1.0        1995-01-31           20000.0   \n",
       "22834           1        0.0     0.0        2005-11-30           25000.0   \n",
       "\n",
       "       BalanceGross  Accept  \n",
       "0               0.0       1  \n",
       "1               0.0       1  \n",
       "2               0.0       1  \n",
       "3               0.0       1  \n",
       "4               0.0       0  \n",
       "...             ...     ...  \n",
       "22830           0.0       1  \n",
       "22831           0.0       1  \n",
       "22832           0.0       1  \n",
       "22833           0.0       1  \n",
       "22834           0.0       0  \n",
       "\n",
       "[22835 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset de entrenamiento con el primer preprocesado\n",
    "df = pd.read_csv('../../../data/processed/df_train.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esos datos preprocesados primeramente, antes de entrenar al modelo realizamos el balanceo usando submuestreo y además, seleccionamos que columnas no van a participar en el proceso de entrenamieto. Se ha decidido no usar esas columnas, ya que de todas las características analizadas, eran las que menos información podían aportar a la hora de clasificar la concesión del crédito. \n",
    "\n",
    "En una primera idea se realizó el entrenamiento con todas las hipótesis planteadas, sin embargo, pese al mal funcionamiento de los modelos de árboles de decisión, se cambió la estrategiay se emplea esta estrategia de seleccionar todas las columnas y descartar las que se cree que no aporta información relevante.\n",
    "\n",
    "En este preprocesado adicional, también se lleva a cabo la codificación de las variables categóricas y se rellenan las variables nulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columnas que no aportan información\n",
    "cols_to_drop = ['id', 'LoanNr_ChkDgt', 'Name', 'ApprovalDate', 'DisbursementDate', 'State']\n",
    "df_clean = df.drop(columns=cols_to_drop)\n",
    "\n",
    "#Codif variables categóricas\n",
    "df_clean = pd.get_dummies(df_clean, columns=['Bank', 'City', 'BankState'], drop_first=True)\n",
    "\n",
    "df_clean.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# Balancear el DataFrame realizando submuestreo \n",
    "# En la columna Accept, el valor 0 corresponde con la clase minoritaria y el 1 la mayoritaria.\n",
    "# Es decir, hay mayor cantidad de datos con préstamos aceptados que rechazados\n",
    "\n",
    "# Extraemos los DataFrames de cada clase\n",
    "df_accept_0 = df_clean[df_clean['Accept'] == 0]\n",
    "df_accept_1 = df_clean[df_clean['Accept'] == 1]\n",
    "\n",
    "# Realizamos un muestreo aleatorio de la clase mayoritaria (1) para igualar el número de la minoritaria (0)\n",
    "n_minority = len(df_accept_0)\n",
    "df_accept_1_under = df_accept_1.sample(n=n_minority, random_state=42)\n",
    "\n",
    "# Combinamos ambas clases y mezclamos los registros\n",
    "df_balanced = pd.concat([df_accept_0, df_accept_1_under]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# df_balanced es el DataFrame final balanceado\n",
    "df_clean = df_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "División del dataset para entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_clean.drop('Accept', axis=1)\n",
    "y = df_clean['Accept']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuración de hiperparámetros de Random Forest y entrenamiento\n",
    "\n",
    "Para llevar a cabo la configuración de los hiperparámetros hemos tenido en cuenta lo la documentación del modelo. Para el criterio de división empleado, se utiliza Gini ya que proporciona una solución rápida y eficiente en la construcción de los árboles. Además, en cuanto al número de estimadores y la profundidad máxima, es decir, como de grande va a ser nuestro bosque y como de profundo va a ser cada árbol se ha optado por valores más altos. El número de estimadores es elevado, ya que como cada árbol de forma individual tiene que dar su valoración, si se poseen gran cantidad de árboles, el error individual promedio disminuye, y por lo tanto, es más robusto pero tiene mayor consumo computacional. Por otro lado, la profundidad del árbol mide la cantidad de decisiones que tiene que realizar cada árbol para tomar una decisión, por lo que se ha fijado en un valor alto, debido a que el conjunto de datos contiene gran cantidad de características, no puede ser muy general porque no se termina de entrenar bien los datos ni muy específico ya que si no se tiende al sobreajuste [1]. Cabe destacar que para seleccionar los parámetros más óptimos y tener la certeza de que eran los adecuados, se ha empleado GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight={0: 5, 1: 2}, max_depth=80,\n",
       "                       n_estimators=500, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight={0: 5, 1: 2}, max_depth=80,\n",
       "                       n_estimators=500, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight={0: 5, 1: 2}, max_depth=80,\n",
       "                       n_estimators=500, random_state=42)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "class_weights = {0: 5, 1: 2}  # Ajusta estos valores según tus datos\n",
    "rf = RandomForestClassifier(\n",
    "    criterion='gini',\n",
    "    n_estimators=500,\n",
    "    max_depth=80,\n",
    "    max_features='sqrt',\n",
    "    class_weight=class_weights,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[592 175]\n",
      " [286 480]]\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.77      0.72       767\n",
      "           1       0.73      0.63      0.68       766\n",
      "\n",
      "    accuracy                           0.70      1533\n",
      "   macro avg       0.70      0.70      0.70      1533\n",
      "weighted avg       0.70      0.70      0.70      1533\n",
      "\n",
      "Macro F1-Score: 0.70\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Matriz de Confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(cm)\n",
    "\n",
    "# Reporte de Clasificación (precision, recall, f1-score, etc.)\n",
    "print(\"Reporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Calculamos el Macro F1-Score\n",
    "macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"Macro F1-Score: {macro_f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, tenemos la comprobación con GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros encontrados:\n",
      "{'max_depth': 80, 'max_features': 'sqrt', 'n_estimators': 500}\n",
      "Matriz de Confusión:\n",
      "[[592 175]\n",
      " [286 480]]\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.77      0.72       767\n",
      "           1       0.73      0.63      0.68       766\n",
      "\n",
      "    accuracy                           0.70      1533\n",
      "   macro avg       0.70      0.70      0.70      1533\n",
      "weighted avg       0.70      0.70      0.70      1533\n",
      "\n",
      "Macro F1-Score: 0.6976687079820924\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, make_scorer\n",
    "\n",
    "# Cargamos el dataset y preprocesar\n",
    "df = pd.read_csv('../../../data/processed/df_train.csv')\n",
    "\n",
    "# Columnas que no aportan información\n",
    "cols_to_drop = ['id', 'LoanNr_ChkDgt', 'Name', 'ApprovalDate', 'DisbursementDate', 'State']\n",
    "df_clean = df.drop(columns=cols_to_drop)\n",
    "\n",
    "#Codif variables categóricas\n",
    "df_clean = pd.get_dummies(df_clean, columns=['Bank', 'City', 'BankState'], drop_first=True)\n",
    "\n",
    "df_clean.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# Balancear el DataFrame realizando submuestreo \n",
    "# En la columna Accept, el valor 0 corresponde con la clase minoritaria y el 1 la mayoritaria.\n",
    "# Es decir, hay mayor cantidad de datos con préstamos aceptados que rechazados\n",
    "\n",
    "# Extraemos los DataFrames de cada clase\n",
    "df_accept_0 = df_clean[df_clean['Accept'] == 0]\n",
    "df_accept_1 = df_clean[df_clean['Accept'] == 1]\n",
    "\n",
    "# Realizamos un muestreo aleatorio de la clase mayoritaria (1) para igualar el número de la minoritaria (0)\n",
    "n_minority = len(df_accept_0)\n",
    "df_accept_1_under = df_accept_1.sample(n=n_minority, random_state=42)\n",
    "\n",
    "# Combinamos ambas clases y mezclamos los registros\n",
    "df_balanced = pd.concat([df_accept_0, df_accept_1_under]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# df_balanced es el DataFrame final balanceado\n",
    "df_clean = df_balanced\n",
    "\n",
    "# Separar X, Y\n",
    "X = df_clean.drop('Accept', axis=1)\n",
    "y = df_clean['Accept']\n",
    "\n",
    "# Dividimos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Definir el grid de hiperparámetros para RandomForestClassifier\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 400, 500],\n",
    "    'max_depth': [None, 10, 20, 40, 80],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Crear un scorer basado en el Macro F1-Score para evaluar el balance entre las clases\n",
    "scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# 5. Configurar y ejecutar GridSearchCV\n",
    "grid_rf = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42, class_weight={0: 5, 1: 2}, n_jobs=10),\n",
    "    param_grid=param_grid,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mejores parámetros encontrados:\")\n",
    "print(grid_rf.best_params_)\n",
    "\n",
    "# 6. Evaluar el mejor modelo en el conjunto de prueba\n",
    "best_rf = grid_rf.best_estimator_\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Macro F1-Score:\", f1_score(y_test, y_pred, average='macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descripción\n",
    "Este modelo también se trata de un algoritmo de aprendizaje supervisado basado en el enfoque de boosting, empleando tamién para las tareas de clsificación y regresión. A diferencia del Random Forest,  XGBoost, se encarga de construir los árboles de manera secuencial, y cada árbol va a intentar corregir los errores producidos por el árbol precedente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación\n",
    "\n",
    "La implementación es muy similar a la utilizada en el Random Forest, a diferencia de la configuracion de los hiperparámetros.\n",
    "\n",
    "Para la configuración, en el caso de XGBoost, el número de estimadores y la profundidad máxima de los árboles se configuraron de manera similar a los valores de Random Forest, siguiendo las recomendaciones de la documentación de XGBoost, y lo indicado por GridSearchCV. Además de estos hiperparámetros, se utilizó la métrica logloss para la evaluación, ya que es especialmente adecuada para problemas de clasificación binaria. Esta métrica penaliza las predicciones incorrectas, lo que mejora la precisión del modelo. También se ha configurado la tasa de aprendizaje del modelo es baja, de tal manera que va a permitir que vaya aprendiendo de forma gradual y sea más generalizable, evitando tender al sobreajuste, y en cada árbol al usar datos con tantas características, se va a emplear un 60% de estas distribuidas de forma aleatoria. [2] [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[588 179]\n",
      " [261 505]]\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.77      0.73       767\n",
      "           1       0.74      0.66      0.70       766\n",
      "\n",
      "    accuracy                           0.71      1533\n",
      "   macro avg       0.72      0.71      0.71      1533\n",
      "weighted avg       0.72      0.71      0.71      1533\n",
      "\n",
      "Macro F1-Score: 0.71\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "\n",
    "# Cargamos el dataset de entrenamiento\n",
    "df = pd.read_csv('../../../data/processed/df_train.csv')\n",
    "\n",
    "\n",
    "# Columnas que no aportan información\n",
    "cols_to_drop = ['id', 'LoanNr_ChkDgt', 'Name', 'ApprovalDate', 'DisbursementDate', 'State']\n",
    "df_clean = df.drop(columns=cols_to_drop)\n",
    "\n",
    "#Codif variables categóricas\n",
    "df_clean = pd.get_dummies(df_clean, columns=['Bank', 'City', 'BankState'], drop_first=True)\n",
    "\n",
    "df_clean.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# Balancear el DataFrame realizando submuestreo \n",
    "# En la columna Accept, el valor 0 corresponde con la clase minoritaria y el 1 la mayoritaria.\n",
    "# Es decir, hay mayor cantidad de datos con préstamos aceptados que rechazados\n",
    "\n",
    "# Extraemos los DataFrames de cada clase\n",
    "df_accept_0 = df_clean[df_clean['Accept'] == 0]\n",
    "df_accept_1 = df_clean[df_clean['Accept'] == 1]\n",
    "\n",
    "# Realizamos un muestreo aleatorio de la clase mayoritaria (1) para igualar el número de la minoritaria (0)\n",
    "n_minority = len(df_accept_0)\n",
    "df_accept_1_under = df_accept_1.sample(n=n_minority, random_state=42)\n",
    "\n",
    "# Combinamos ambas clases y mezclamos los registros\n",
    "df_balanced = pd.concat([df_accept_0, df_accept_1_under]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# df_balanced es el DataFrame final balanceado\n",
    "df_clean = df_balanced\n",
    "\n",
    "#Separamos X, Y\n",
    "X = df_clean.drop('Accept', axis=1)\n",
    "y = df_clean['Accept']\n",
    "\n",
    "# Dividimos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Configuración y entrenamiento del modelo\n",
    "# Se asigna un peso de 5 a la clase 0 (créditos rechazados) y 2 a la clase 1 (créditos aceptados)\n",
    "sample_weights = y_train.map({0: 5, 1: 2})\n",
    "\n",
    "# Inicializamos y entrenamos el modelo XGBoost\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=80,\n",
    "    learning_rate=0.05,\n",
    "    eval_metric='logloss',\n",
    "    colsample_bytree = 0.6,\n",
    "    random_state=42\n",
    ")\n",
    "xgb.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "# Realizamos predicciones en el conjunto de prueba\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "# Evaluamos el modelo\n",
    "\n",
    "# Matriz de Confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(cm)\n",
    "\n",
    "# Reporte de Clasificación\n",
    "print(\"Reporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Calcular el Macro F1-Score\n",
    "macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"Macro F1-Score: {macro_f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, tenemos la comprobación con GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n",
      "Mejores parámetros encontrados:\n",
      "{'colsample_bytree': 0.6, 'learning_rate': 0.05, 'max_depth': 80, 'n_estimators': 100}\n",
      "Matriz de Confusión:\n",
      "[[608 159]\n",
      " [273 493]]\n",
      "Clase 0 SON CRÉDITOS RECHAZADOS y Clase 1 son CRÉDITOS ACEPTADOS\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.79      0.74       767\n",
      "           1       0.76      0.64      0.70       766\n",
      "\n",
      "    accuracy                           0.72      1533\n",
      "   macro avg       0.72      0.72      0.72      1533\n",
      "weighted avg       0.72      0.72      0.72      1533\n",
      "\n",
      "Macro F1-Score: 0.72\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "\n",
    "# Cargamos el dataset de entrenamiento\n",
    "df = pd.read_csv('../../../data/processed/df_train.csv')\n",
    "\n",
    "cols_to_drop = ['id', 'LoanNr_ChkDgt', 'Name', 'ApprovalDate', 'DisbursementDate', 'State']\n",
    "df_clean = df.drop(columns=cols_to_drop)\n",
    "\n",
    "# Codificar variables categóricas\n",
    "df_clean = pd.get_dummies(df_clean, columns=['Bank', 'City', 'BankState'], drop_first=True)\n",
    "df_clean.fillna(0, inplace=True)\n",
    "\n",
    "# Balancear el DataFrame realizando submuestreo \n",
    "# En la columna Accept, el valor 0 corresponde con la clase minoritaria y el 1 la mayoritaria.\n",
    "# Es decir, hay mayor cantidad de datos con préstamos aceptados que rechazados\n",
    "\n",
    "# Extraemos los DataFrames de cada clase\n",
    "df_accept_0 = df_clean[df_clean['Accept'] == 0]\n",
    "df_accept_1 = df_clean[df_clean['Accept'] == 1]\n",
    "\n",
    "# Realizamos un muestreo aleatorio de la clase mayoritaria (1) para igualar el número de la minoritaria (0)\n",
    "n_minority = len(df_accept_0)\n",
    "df_accept_1_under = df_accept_1.sample(n=n_minority, random_state=42)\n",
    "\n",
    "# Combinamos ambas clases y mezclamos los registros\n",
    "df_balanced = pd.concat([df_accept_0, df_accept_1_under]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# df_balanced es el DataFrame final balanceado\n",
    "df_clean = df_balanced\n",
    "\n",
    "#Separamos X, Y\n",
    "X = df_clean.drop('Accept', axis=1)\n",
    "y = df_clean['Accept']\n",
    "\n",
    "# Dividimos el dataset de forma estratificada (80% entrenamiento, 20% prueba)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "sample_weights = y_train.map({0: 5, 1: 2})\n",
    "\n",
    "# Definimos el modelo XGBoost\n",
    "xgb = XGBClassifier(\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Definimos el rango de parámetros para GridSearch\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],          # Número de árboles\n",
    "    'max_depth': [3, 5, 6, 10, 50, 80],               # Profundidad de los árboles\n",
    "    'learning_rate': [0.01, 0.05, 0.1],       # Tasa de aprendizaje\n",
    "    'colsample_bytree': [1, 0.6, 0.8]\n",
    "}\n",
    "\n",
    "# Realizamos GridSearchCV para encontrar los mejores hiperparámetros\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=3, n_jobs=-1, verbose=1, scoring='f1_macro')\n",
    "grid_search.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "# Imprimimos los mejores parámetros encontrados\n",
    "print(\"Mejores parámetros encontrados:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Usamos el mejor modelo encontrado por GridSearch\n",
    "best_xgb = grid_search.best_estimator_\n",
    "\n",
    "# Realizamos predicciones en el conjunto de prueba\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "\n",
    "# Evaluamos el modelo\n",
    "\n",
    "# Matriz de Confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(cm)\n",
    "\n",
    "# Reporte de Clasificación\n",
    "print(\"Reporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Calcular el Macro F1-Score\n",
    "macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"Macro F1-Score: {macro_f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble del Random Forest y XGBoost\n",
    "\n",
    "Finalmente con estos dos modelos hemos realizado un ensemble, que va a permitir realizar un aprendizaje automático conjunto, para mejorar la precisión y robustez del modelo, en lugar de emplear únicamente uno de los dos modelos mencionados. \n",
    "\n",
    "Para ello, se estudió dos tipos de ensemble:\n",
    "1. Voting Classifier\n",
    "2. Stacking Classifier\n",
    "\n",
    "Después de un análisis de los dos, el que mejor funcionaba para nuestro conjunto de datos se trataba del Voting Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier \n",
    "\n",
    "Esta técnica combina las predicciones de ambos modelos. Se puede elegir entre:\n",
    "\n",
    "* Hard Voting: Cada modelo vota por una clase y se toma la mayoría.\n",
    "\n",
    "* Soft Voting: Se promedian las probabilidades de cada clase y se selecciona la de mayor probabilidad final.\n",
    "\n",
    "[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementación con Voting Classifier:\n",
    "\n",
    "La implementación es similar a los dos modelos anteriores con las configuraciones ya establecidas. Cabe resaltar que hemos obtado por una votación de tipo suave, la cuál es menos agresiva y clasifica mejor los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[573 194]\n",
      " [252 514]]\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.75      0.72       767\n",
      "           1       0.73      0.67      0.70       766\n",
      "\n",
      "    accuracy                           0.71      1533\n",
      "   macro avg       0.71      0.71      0.71      1533\n",
      "weighted avg       0.71      0.71      0.71      1533\n",
      "\n",
      "Macro F1-Score: 0.7086356136176132\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "# Cargar el dataset\n",
    "df = pd.read_csv('../../../data/processed/df_train.csv')\n",
    "\n",
    "# Eliminamos columnas irrelevantes\n",
    "cols_to_drop = ['id', 'LoanNr_ChkDgt', 'Name', 'ApprovalDate', 'DisbursementDate', 'State']\n",
    "df_clean = df.drop(columns=cols_to_drop)\n",
    "\n",
    "# Codificamos variables categóricas a dummy\n",
    "df_clean = pd.get_dummies(df_clean, columns=['Bank', 'City', 'BankState'], drop_first=True)\n",
    "\n",
    "df_clean.fillna(0, inplace=True)\n",
    "\n",
    "# Balancear el DataFrame realizando submuestreo \n",
    "# En la columna Accept, el valor 0 corresponde con la clase minoritaria y el 1 la mayoritaria.\n",
    "# Es decir, hay mayor cantidad de datos con préstamos aceptados que rechazados\n",
    "\n",
    "# Extraemos los DataFrames de cada clase\n",
    "df_accept_0 = df_clean[df_clean['Accept'] == 0]\n",
    "df_accept_1 = df_clean[df_clean['Accept'] == 1]\n",
    "\n",
    "# Realizamos un muestreo aleatorio de la clase mayoritaria (1) para igualar el número de la minoritaria (0)\n",
    "n_minority = len(df_accept_0)\n",
    "df_accept_1_under = df_accept_1.sample(n=n_minority, random_state=42)\n",
    "\n",
    "# Combinamos ambas clases y mezclamos los registros\n",
    "df_balanced = pd.concat([df_accept_0, df_accept_1_under]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# df_balanced es el DataFrame final balanceado\n",
    "df_clean = df_balanced\n",
    "\n",
    "#Separamos X, Y\n",
    "X = df_clean.drop('Accept', axis=1)\n",
    "y = df_clean['Accept']\n",
    "\n",
    "# División de los datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Definimos los dos modelos\n",
    "rf = RandomForestClassifier(\n",
    "    criterion='gini',\n",
    "    n_estimators=500,\n",
    "    max_depth=80,\n",
    "    max_features='sqrt',\n",
    "    class_weight={0:5, 1:2},\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth= 80,\n",
    "    learning_rate=0.05,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Combinamos los modelos con VotingClassifier (voting='soft' para promediar probabilidades)\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('rf', rf), ('xgb', xgb_model)],\n",
    "    voting='soft', \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Entrenamos el ensemble\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluamos el ensemble\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Macro F1-Score:\", f1_score(y_test, y_pred, average='macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "El Voting Classifier que combina RandomForest y XGBoost, demuestra un rendimiento sólido con un \"accuracy\" de 0.71 y un Macro F1-Score de 0.71, siendo el modelo más robusto de los 3 analizados. Una accuracy de 0.71 implica la proporción de predicciones correctas sobre el total de las predicciones realizadas, por lo que para el 71% de los datos del conjunto se clasifican correctamente. Además, la macro F1-score, nos indica que el modelo tiene buen desempeño tanto para identificar correctamente los positivos (recall) como la precisión de las predicciones. Si analizamos en profundidad, este modelo presenta un recall del 75% para los prestamos rechazados y un 67% para los préstamos aceptados, lo que refleja un buen desempeño  en la clasificación de la clase minotoria, gracias al balanceo de los datos. El modelo ha aprendido a categorizar adecuadamente los préstamos rechazados, mejorando su capacidad de predección para esta clase.\n",
    "\n",
    "Al comparar los modelos individuales a través de la validación cruzada, se observa que para estos tres modelos, las métricas obtenidas son bastante similares, indicando que los modelos son estables y robustos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Cross-validation score mean: 0.7130\n",
      "XGBoost - Cross-validation score mean: 0.6973\n",
      "VotingClassifier - Cross-validation score mean: 0.7073\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset\n",
    "df = pd.read_csv('../../../data/processed/df_train.csv')\n",
    "\n",
    "# Preprocesado\n",
    "cols_to_drop = ['id', 'LoanNr_ChkDgt', 'Name', 'ApprovalDate', 'DisbursementDate', 'State']\n",
    "df_clean = df.drop(columns=cols_to_drop)\n",
    "\n",
    "# Convertir variables categóricas a dummy\n",
    "df_clean = pd.get_dummies(df_clean, columns=['Bank', 'City', 'BankState'], drop_first=True)\n",
    "\n",
    "# Imputar valores nulos\n",
    "df_clean.fillna(0, inplace=True)\n",
    "\n",
    "# Balanceo del DataFrame\n",
    "df_accept_0 = df_clean[df_clean['Accept'] == 0]\n",
    "df_accept_1 = df_clean[df_clean['Accept'] == 1]\n",
    "n_minority = len(df_accept_0)\n",
    "df_accept_1_under = df_accept_1.sample(n=n_minority, random_state=42)\n",
    "df_balanced = pd.concat([df_accept_0, df_accept_1_under]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Separar features y target\n",
    "X = df_balanced.drop('Accept', axis=1)\n",
    "y = df_balanced['Accept']\n",
    "\n",
    "# Definir modelos\n",
    "rf = RandomForestClassifier(n_estimators=500, max_depth=80, max_features='sqrt', class_weight={0:5, 1:2}, random_state=42)\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=200, max_depth=80, learning_rate=0.05, eval_metric='logloss', colsample_bytree=0.6, random_state=42)\n",
    "voting_clf = VotingClassifier(estimators=[('rf', rf), ('xgb', xgb_model)], voting='soft', n_jobs=-1)\n",
    "\n",
    "# Validación cruzada para Random Forest\n",
    "rf_scores = cross_val_score(rf, X, y, cv=5)\n",
    "print(f\"Random Forest - Cross-validation score mean: {rf_scores.mean():.4f}\")\n",
    "\n",
    "# Validación cruzada para XGBoost\n",
    "xgb_scores = cross_val_score(xgb_model, X, y, cv=5)\n",
    "print(f\"XGBoost - Cross-validation score mean: {xgb_scores.mean():.4f}\")\n",
    "\n",
    "# Validación cruzada para el VotingClassifier\n",
    "voting_scores = cross_val_score(voting_clf, X, y, cv=5)\n",
    "print(f\"VotingClassifier - Cross-validation score mean: {voting_scores.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "- [RandomForestClassifier - Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "- [XGBoost Parameters - XGBoost Documentation](https://xgboost.readthedocs.io/en/release_3.0.0/parameter.html)\n",
    "- [XGBoost Hyperparameters - AWS SageMaker](https://docs.aws.amazon.com/es_es/sagemaker/latest/dg/xgboost_hyperparameters.html)\n",
    "\n",
    "- [VotingClassifier - Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
