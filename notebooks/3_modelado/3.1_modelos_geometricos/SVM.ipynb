{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General import and load data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Training and test spliting\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Preprocessing \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Estimators\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Evaluation\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Optimization\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>LoanNr_ChkDgt</th>\n",
       "      <th>Name</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Bank</th>\n",
       "      <th>BankState</th>\n",
       "      <th>ApprovalDate</th>\n",
       "      <th>ApprovalFY</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>...</th>\n",
       "      <th>CreateJob</th>\n",
       "      <th>RetainedJob</th>\n",
       "      <th>FranchiseCode</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>LowDoc</th>\n",
       "      <th>DisbursementDate</th>\n",
       "      <th>DisbursementGross</th>\n",
       "      <th>BalanceGross</th>\n",
       "      <th>Accept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bd9d6267ec5</td>\n",
       "      <td>1523195006</td>\n",
       "      <td>P-SCAPE LAND DESIGN, LLC</td>\n",
       "      <td>NORTHFIELD</td>\n",
       "      <td>OH</td>\n",
       "      <td>CITIZENS BANK NATL ASSOC</td>\n",
       "      <td>RI</td>\n",
       "      <td>2005-11-01</td>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2005-12-31</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9eebf6d8098</td>\n",
       "      <td>1326365010</td>\n",
       "      <td>The Fresh &amp; Healthy Catering C</td>\n",
       "      <td>CANTON</td>\n",
       "      <td>OH</td>\n",
       "      <td>FIRSTMERIT BANK, N.A.</td>\n",
       "      <td>OH</td>\n",
       "      <td>2005-06-06</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2005-07-31</td>\n",
       "      <td>166000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83806858500</td>\n",
       "      <td>6179584001</td>\n",
       "      <td>AARON MASON &amp; HOWE LLC</td>\n",
       "      <td>SAWYERWOOD</td>\n",
       "      <td>OH</td>\n",
       "      <td>PNC BANK, NATIONAL ASSOCIATION</td>\n",
       "      <td>OH</td>\n",
       "      <td>2003-03-18</td>\n",
       "      <td>2003</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2003-03-31</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a21ab9cb3af</td>\n",
       "      <td>8463493009</td>\n",
       "      <td>MID OHIO CAR WASH</td>\n",
       "      <td>COLUMBUS</td>\n",
       "      <td>OH</td>\n",
       "      <td>THE HUNTINGTON NATIONAL BANK</td>\n",
       "      <td>OH</td>\n",
       "      <td>1995-06-28</td>\n",
       "      <td>1995</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1996-01-31</td>\n",
       "      <td>220100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>883b5e5385e</td>\n",
       "      <td>3382225007</td>\n",
       "      <td>Bake N Brew LLC</td>\n",
       "      <td>Newark</td>\n",
       "      <td>OH</td>\n",
       "      <td>THE HUNTINGTON NATIONAL BANK</td>\n",
       "      <td>OH</td>\n",
       "      <td>2009-04-16</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009-05-31</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  LoanNr_ChkDgt                            Name        City  \\\n",
       "0  bd9d6267ec5     1523195006        P-SCAPE LAND DESIGN, LLC  NORTHFIELD   \n",
       "1  9eebf6d8098     1326365010  The Fresh & Healthy Catering C      CANTON   \n",
       "2  83806858500     6179584001          AARON MASON & HOWE LLC  SAWYERWOOD   \n",
       "3  a21ab9cb3af     8463493009               MID OHIO CAR WASH    COLUMBUS   \n",
       "4  883b5e5385e     3382225007                 Bake N Brew LLC      Newark   \n",
       "\n",
       "  State                            Bank BankState ApprovalDate  ApprovalFY  \\\n",
       "0    OH        CITIZENS BANK NATL ASSOC        RI   2005-11-01        2006   \n",
       "1    OH           FIRSTMERIT BANK, N.A.        OH   2005-06-06        2005   \n",
       "2    OH  PNC BANK, NATIONAL ASSOCIATION        OH   2003-03-18        2003   \n",
       "3    OH    THE HUNTINGTON NATIONAL BANK        OH   1995-06-28        1995   \n",
       "4    OH    THE HUNTINGTON NATIONAL BANK        OH   2009-04-16        2009   \n",
       "\n",
       "   NoEmp  ...  CreateJob  RetainedJob  FranchiseCode  UrbanRural  RevLineCr  \\\n",
       "0      2  ...          0            2              0           1        0.0   \n",
       "1      2  ...          1            2              1           1        0.0   \n",
       "2      2  ...          4            2              1           2        1.0   \n",
       "3      2  ...          0            0              1           0        0.0   \n",
       "4      0  ...          0            0              0           1        0.0   \n",
       "\n",
       "   LowDoc  DisbursementDate DisbursementGross  BalanceGross  Accept  \n",
       "0     0.0        2005-12-31            8000.0           0.0       1  \n",
       "1     0.0        2005-07-31          166000.0           0.0       1  \n",
       "2     0.0        2003-03-31           25000.0           0.0       1  \n",
       "3     0.0        1996-01-31          220100.0           0.0       1  \n",
       "4     0.0        2009-05-31           25000.0           0.0       0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"/home/ines/dev/CDAW_reto1/LBBYs/data/processed/df_train.csv\"\n",
    "df = pd.read_csv(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submuestreo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    object\n",
       "LoanNr_ChkDgt          int64\n",
       "Name                  object\n",
       "City                  object\n",
       "State                 object\n",
       "Bank                  object\n",
       "BankState             object\n",
       "ApprovalDate          object\n",
       "ApprovalFY             int64\n",
       "NoEmp                  int64\n",
       "NewExist             float64\n",
       "CreateJob              int64\n",
       "RetainedJob            int64\n",
       "FranchiseCode          int64\n",
       "UrbanRural             int64\n",
       "RevLineCr            float64\n",
       "LowDoc               float64\n",
       "DisbursementDate      object\n",
       "DisbursementGross    float64\n",
       "BalanceGross         float64\n",
       "Accept                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separar clases mayoritaria y minoritaria\n",
    "df_majority = df[df[\"Accept\"] == 1]  # Créditos aceptados (clase mayoritaria)\n",
    "df_minority = df[df[\"Accept\"] == 0]  # Créditos no aceptados (clase minoritaria)\n",
    "\n",
    "# Aplicar Submuestreo (undersampling)\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                   replace=False,  # Sin reemplazo\n",
    "                                   n_samples=len(df_minority),  # Igualar cantidad de muestras\n",
    "                                   random_state=42)  # Fijar semilla\n",
    "\n",
    "# Unir el dataset balanceado\n",
    "df_balanced = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "# Mezclar los datos para evitar sesgos\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Bank</th>\n",
       "      <th>BankState</th>\n",
       "      <th>ApprovalFY</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>NewExist</th>\n",
       "      <th>CreateJob</th>\n",
       "      <th>RetainedJob</th>\n",
       "      <th>FranchiseCode</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>LowDoc</th>\n",
       "      <th>DisbursementGross</th>\n",
       "      <th>BalanceGross</th>\n",
       "      <th>Accept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Greenwillow</td>\n",
       "      <td>THE HUNTINGTON NATIONAL BANK</td>\n",
       "      <td>OH</td>\n",
       "      <td>2007</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COLUMBUS</td>\n",
       "      <td>THE HUNTINGTON NATIONAL BANK</td>\n",
       "      <td>OH</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reynoldsburg</td>\n",
       "      <td>BUSINESS LOAN CENTER, LLC</td>\n",
       "      <td>FL</td>\n",
       "      <td>2006</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WESTLAKE</td>\n",
       "      <td>CITIZENS BANK NATL ASSOC</td>\n",
       "      <td>RI</td>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SHAWNEE HILLS</td>\n",
       "      <td>THE HUNTINGTON NATIONAL BANK</td>\n",
       "      <td>OH</td>\n",
       "      <td>1999</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City                          Bank BankState  ApprovalFY  NoEmp  \\\n",
       "0    Greenwillow  THE HUNTINGTON NATIONAL BANK        OH        2007      5   \n",
       "2       COLUMBUS  THE HUNTINGTON NATIONAL BANK        OH        2008      4   \n",
       "3   Reynoldsburg     BUSINESS LOAN CENTER, LLC        FL        2006      3   \n",
       "4       WESTLAKE      CITIZENS BANK NATL ASSOC        RI        2006      2   \n",
       "5  SHAWNEE HILLS  THE HUNTINGTON NATIONAL BANK        OH        1999      5   \n",
       "\n",
       "   NewExist  CreateJob  RetainedJob  FranchiseCode  UrbanRural  RevLineCr  \\\n",
       "0       1.0          0            1              0           1        0.0   \n",
       "2       0.0          0            4              1           1        0.0   \n",
       "3       1.0          0            3              0           1        0.0   \n",
       "4       0.0          0            2              0           1        0.0   \n",
       "5       1.0          5            0              1           1        0.0   \n",
       "\n",
       "   LowDoc  DisbursementGross  BalanceGross  Accept  \n",
       "0     0.0            31000.0           0.0       0  \n",
       "2     0.0            50000.0           0.0       1  \n",
       "3     0.0            25000.0           0.0       0  \n",
       "4     0.0            42000.0           0.0       1  \n",
       "5     0.0           150000.0           0.0       0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminar filas con NaN en las columnas relevantes\n",
    "df_balanced= df_balanced.dropna()\n",
    "cols_to_drop = ['id', 'LoanNr_ChkDgt', 'Name', 'ApprovalDate', 'DisbursementDate', 'State']\n",
    "df_balanced = df_balanced.drop(columns=cols_to_drop)\n",
    "\n",
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UrbanRural\n",
       "1    4193\n",
       "0    1974\n",
       "2    1423\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = df_balanced[\"UrbanRural\"].value_counts()\n",
    "var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hipótesis 1: Impacto de la ubicación (City) en la probabilidad de aprobación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] END ......................................C=10, gamma=1; total time=   0.7s\n",
      "[CV] END ......................................C=10, gamma=1; total time=   0.7s\n",
      "[CV] END ......................................C=10, gamma=1; total time=   0.7s\n",
      "[CV] END ......................................C=10, gamma=1; total time=   0.7s\n",
      "[CV] END ......................................C=10, gamma=1; total time=   0.7s\n",
      "[CV] END ....................................C=10, gamma=0.1; total time=   0.6s\n",
      "[CV] END ....................................C=10, gamma=0.1; total time=   0.5s\n",
      "[CV] END ....................................C=10, gamma=0.1; total time=   0.5s\n",
      "[CV] END ....................................C=10, gamma=0.1; total time=   0.5s\n",
      "[CV] END ....................................C=10, gamma=0.1; total time=   0.5s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=   0.5s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=   0.5s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=   0.5s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=   0.5s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=   0.5s\n",
      "[CV] END .....................................C=100, gamma=1; total time=   0.6s\n",
      "[CV] END .....................................C=100, gamma=1; total time=   0.6s\n",
      "[CV] END .....................................C=100, gamma=1; total time=   0.6s\n",
      "[CV] END .....................................C=100, gamma=1; total time=   0.7s\n",
      "[CV] END .....................................C=100, gamma=1; total time=   0.6s\n",
      "[CV] END ...................................C=100, gamma=0.1; total time=   0.8s\n",
      "[CV] END ...................................C=100, gamma=0.1; total time=   0.7s\n",
      "[CV] END ...................................C=100, gamma=0.1; total time=   0.7s\n",
      "[CV] END ...................................C=100, gamma=0.1; total time=   0.6s\n",
      "[CV] END ...................................C=100, gamma=0.1; total time=   0.9s\n",
      "[CV] END ..................................C=100, gamma=0.01; total time=   0.7s\n",
      "[CV] END ..................................C=100, gamma=0.01; total time=   0.5s\n",
      "[CV] END ..................................C=100, gamma=0.01; total time=   0.5s\n",
      "[CV] END ..................................C=100, gamma=0.01; total time=   0.5s\n",
      "[CV] END ..................................C=100, gamma=0.01; total time=   0.5s\n",
      "Mejores parámetros encontrados: {'C': 100, 'gamma': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Primero, eliminar filas con valores faltantes en las columnas relevantes\n",
    "cols_relevantes = ['UrbanRural', 'NoEmp', 'NewExist', 'Accept']\n",
    "df_balanced = df_balanced.dropna(subset=cols_relevantes)\n",
    "\n",
    "# Seleccionar variables predictoras y variable objetivo\n",
    "X = df_balanced[['UrbanRural', 'NoEmp', 'NewExist']]\n",
    "y = df_balanced['Accept']\n",
    "\n",
    "# Convertir la variable categórica 'UrbanRural' a variables dummy\n",
    "X = pd.get_dummies(X, columns=['UrbanRural'], drop_first=True)\n",
    "\n",
    "# División en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Escalado de las características\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Definir el grid de hiperparámetros para el SVM\n",
    "param_grid = {\n",
    "    'C': [10, 100],\n",
    "    'gamma': [1, 0.1, 0.01]\n",
    "}\n",
    "\n",
    "# Configurar GridSearchCV con SVC (kernel 'rbf')\n",
    "grid = GridSearchCV(SVC(kernel='rbf', random_state=42, class_weight='balanced'),\n",
    "                    param_grid, cv=5, verbose=2)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Mejores parámetros encontrados:\", grid.best_params_)\n",
    "\n",
    "# Usar el mejor modelo para predecir en el conjunto de prueba\n",
    "y_pred = grid.predict(X_test_scaled)\n",
    "\n",
    "# Evaluar el modelo\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[976 180]\n",
      " [703 439]]\n",
      "Accuracy: 0.6157528285465622\n",
      "Precision: 0.7092084006462036\n",
      "Recall: 0.38441330998248685\n",
      "F1-score: 0.498580352072686\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.84      0.69      1156\n",
      "           1       0.71      0.38      0.50      1142\n",
      "\n",
      "    accuracy                           0.62      2298\n",
      "   macro avg       0.65      0.61      0.59      2298\n",
      "weighted avg       0.64      0.62      0.59      2298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Matriz de Confusión:\")\n",
    "print(cm)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1-score:\", f1)\n",
    "print(\"Reporte de clasificación:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Hipótesis 2: \"Impacto de la ubicación geográfica (Urban vs Rural) en la aprobación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .......................................C=1, gamma=1; total time=   0.4s\n",
      "[CV] END .......................................C=1, gamma=1; total time=   0.4s\n",
      "[CV] END .......................................C=1, gamma=1; total time=   0.4s\n",
      "[CV] END .......................................C=1, gamma=1; total time=   0.4s\n",
      "[CV] END .......................................C=1, gamma=1; total time=   0.4s\n",
      "[CV] END .....................................C=1, gamma=0.1; total time=   0.4s\n",
      "[CV] END .....................................C=1, gamma=0.1; total time=   0.4s\n",
      "[CV] END .....................................C=1, gamma=0.1; total time=   0.4s\n",
      "[CV] END .....................................C=1, gamma=0.1; total time=   0.4s\n",
      "[CV] END .....................................C=1, gamma=0.1; total time=   0.4s\n",
      "[CV] END ....................................C=1, gamma=0.01; total time=   0.4s\n",
      "[CV] END ....................................C=1, gamma=0.01; total time=   0.4s\n",
      "[CV] END ....................................C=1, gamma=0.01; total time=   0.4s\n",
      "[CV] END ....................................C=1, gamma=0.01; total time=   0.4s\n",
      "[CV] END ....................................C=1, gamma=0.01; total time=   0.4s\n",
      "[CV] END ......................................C=10, gamma=1; total time=   0.4s\n",
      "[CV] END ......................................C=10, gamma=1; total time=   0.4s\n",
      "[CV] END ......................................C=10, gamma=1; total time=   0.4s\n",
      "[CV] END ......................................C=10, gamma=1; total time=   0.4s\n",
      "[CV] END ......................................C=10, gamma=1; total time=   0.4s\n",
      "[CV] END ....................................C=10, gamma=0.1; total time=   0.4s\n",
      "[CV] END ....................................C=10, gamma=0.1; total time=   0.4s\n",
      "[CV] END ....................................C=10, gamma=0.1; total time=   0.4s\n",
      "[CV] END ....................................C=10, gamma=0.1; total time=   0.4s\n",
      "[CV] END ....................................C=10, gamma=0.1; total time=   0.4s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=   0.4s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=   0.4s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=   0.4s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=   0.4s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=   0.4s\n",
      "[CV] END .....................................C=100, gamma=1; total time=   0.4s\n",
      "[CV] END .....................................C=100, gamma=1; total time=   0.4s\n",
      "[CV] END .....................................C=100, gamma=1; total time=   0.4s\n",
      "[CV] END .....................................C=100, gamma=1; total time=   0.4s\n",
      "[CV] END .....................................C=100, gamma=1; total time=   0.4s\n",
      "[CV] END ...................................C=100, gamma=0.1; total time=   0.4s\n",
      "[CV] END ...................................C=100, gamma=0.1; total time=   0.4s\n",
      "[CV] END ...................................C=100, gamma=0.1; total time=   0.4s\n",
      "[CV] END ...................................C=100, gamma=0.1; total time=   0.4s\n",
      "[CV] END ...................................C=100, gamma=0.1; total time=   0.4s\n",
      "[CV] END ..................................C=100, gamma=0.01; total time=   0.4s\n",
      "[CV] END ..................................C=100, gamma=0.01; total time=   0.4s\n",
      "[CV] END ..................................C=100, gamma=0.01; total time=   0.4s\n",
      "[CV] END ..................................C=100, gamma=0.01; total time=   0.4s\n",
      "[CV] END ..................................C=100, gamma=0.01; total time=   0.4s\n",
      "Mejores parámetros encontrados para Hipótesis 2: {'C': 1, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "df_balanced['UrbanRural'] = df_balanced['UrbanRural'].astype(str).str.lower()\n",
    "\n",
    "# Asegurarse de que la columna 'UrbanRural' esté en minúsculas\n",
    "df_balanced['UrbanRural'] = df_balanced['UrbanRural'].str.lower()\n",
    "\n",
    "# Eliminar filas con valores faltantes en las columnas relevantes\n",
    "cols_relevantes = ['UrbanRural', 'Accept']\n",
    "df_balanced = df_balanced.dropna(subset=cols_relevantes)\n",
    "\n",
    "# Seleccionar la variable predictora y la variable objetivo\n",
    "X2 = df_balanced[['UrbanRural']]\n",
    "y2 = df_balanced['Accept']\n",
    "\n",
    "# Convertir la variable categórica 'UrbanRural' a variables dummy\n",
    "# Por ejemplo, si los valores son \"urban\" y \"rural\", se creará una columna \"UrbanRural_urban\"\n",
    "X2 = pd.get_dummies(X2, columns=['UrbanRural'], drop_first=True)\n",
    "\n",
    "# División en conjuntos de entrenamiento y prueba\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.3, random_state=42)\n",
    "\n",
    "# Escalado de las características\n",
    "scaler2 = StandardScaler()\n",
    "X2_train_scaled = scaler2.fit_transform(X2_train)\n",
    "X2_test_scaled = scaler2.transform(X2_test)\n",
    "\n",
    "# Definir el grid de hiperparámetros para el SVM\n",
    "param_grid2 = {\n",
    "    'C': [1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01]\n",
    "}\n",
    "\n",
    "# Configurar GridSearchCV con SVC (kernel 'rbf') y balanceo de clases\n",
    "grid2 = GridSearchCV(SVC(kernel='rbf', random_state=42, class_weight='balanced'),\n",
    "                     param_grid2, cv=5, verbose=2)\n",
    "grid2.fit(X2_train_scaled, y2_train)\n",
    "\n",
    "print(\"Mejores parámetros encontrados para Hipótesis 2:\", grid2.best_params_)\n",
    "\n",
    "# Usar el mejor modelo para predecir en el conjunto de prueba\n",
    "y2_pred = grid2.predict(X2_test_scaled)\n",
    "\n",
    "# Evaluación del modelo\n",
    "cm2 = confusion_matrix(y2_test, y2_pred)\n",
    "acc2 = accuracy_score(y2_test, y2_pred)\n",
    "prec2 = precision_score(y2_test, y2_pred)\n",
    "rec2 = recall_score(y2_test, y2_pred)\n",
    "f12 = f1_score(y2_test, y2_pred)\n",
    "report2 = classification_report(y2_test, y2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión (Hipótesis 2):\n",
      "[[979 177]\n",
      " [708 434]]\n",
      "Accuracy: 0.6148825065274152\n",
      "Precision: 0.7103109656301145\n",
      "Recall: 0.38003502626970226\n",
      "F1-score: 0.49515116942384485\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.85      0.69      1156\n",
      "           1       0.71      0.38      0.50      1142\n",
      "\n",
      "    accuracy                           0.61      2298\n",
      "   macro avg       0.65      0.61      0.59      2298\n",
      "weighted avg       0.64      0.61      0.59      2298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Matriz de Confusión (Hipótesis 2):\")\n",
    "print(cm2)\n",
    "print(\"Accuracy:\", acc2)\n",
    "print(\"Precision:\", prec2)\n",
    "print(\"Recall:\", rec2)\n",
    "print(\"F1-score:\", f12)\n",
    "print(\"Reporte de clasificación:\")\n",
    "print(report2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar columnas irrelevantes\n",
    "cols_to_drop = ['LoanNr_ChkDgt', 'Name', 'ApprovalDate', 'DisbursementDate', 'State']\n",
    "df_balanced = df_balanced.drop(columns=cols_to_drop)\n",
    "\n",
    "# Eliminar filas con valores faltantes en todas las columnas restantes\n",
    "df_balanced = df_balanced.dropna()\n",
    "\n",
    "# Separar la variable objetivo y los predictores\n",
    "y = df_balanced['Accept']\n",
    "X = df_balanced.drop(columns=['Accept'])\n",
    "\n",
    "# Convertir todas las columnas categóricas a variables dummy\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Escalar las características\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Definir el grid de hiperparámetros para el SVM\n",
    "param_grid = {\n",
    "    'C': [10, 100],\n",
    "    'gamma': [1, 0.1, 0.01]\n",
    "}\n",
    "\n",
    "# Configurar GridSearchCV con SVC (kernel 'rbf')\n",
    "grid = GridSearchCV(SVC(kernel='rbf', random_state=42, class_weight='balanced'),\n",
    "                    param_grid, cv=5, verbose=2)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Mejores parámetros encontrados:\", grid.best_params_)\n",
    "\n",
    "# Usar el mejor modelo para predecir en el conjunto de prueba\n",
    "y_pred = grid.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[723 377]\n",
      " [471 712]]\n",
      "Accuracy: 0.6285589137100307\n",
      "Precision: 0.6538108356290174\n",
      "Recall: 0.6018596787827557\n",
      "F1-score: 0.6267605633802817\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.66      0.63      1100\n",
      "           1       0.65      0.60      0.63      1183\n",
      "\n",
      "    accuracy                           0.63      2283\n",
      "   macro avg       0.63      0.63      0.63      2283\n",
      "weighted avg       0.63      0.63      0.63      2283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluar el modelo\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(cm)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1-score:\", f1)\n",
    "print(\"Reporte de clasificación:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] END .......................................C=1, gamma=1; total time=  16.0s\n",
      "[CV] END .......................................C=1, gamma=1; total time=  14.8s\n",
      "[CV] END .......................................C=1, gamma=1; total time=  14.7s\n",
      "[CV] END .......................................C=1, gamma=1; total time=  15.3s\n",
      "[CV] END .......................................C=1, gamma=1; total time=  15.6s\n",
      "[CV] END .....................................C=1, gamma=0.1; total time=  14.8s\n",
      "[CV] END .....................................C=1, gamma=0.1; total time=  15.3s\n",
      "[CV] END .....................................C=1, gamma=0.1; total time=  15.1s\n",
      "[CV] END .....................................C=1, gamma=0.1; total time=  14.9s\n",
      "[CV] END .....................................C=1, gamma=0.1; total time=  14.8s\n",
      "[CV] END ....................................C=1, gamma=0.01; total time=  14.1s\n",
      "[CV] END ....................................C=1, gamma=0.01; total time=  14.1s\n",
      "[CV] END ....................................C=1, gamma=0.01; total time=  14.0s\n",
      "[CV] END ....................................C=1, gamma=0.01; total time=  13.9s\n",
      "[CV] END ....................................C=1, gamma=0.01; total time=  14.1s\n",
      "[CV] END ......................................C=10, gamma=1; total time=  15.6s\n",
      "[CV] END ......................................C=10, gamma=1; total time=  16.1s\n",
      "[CV] END ......................................C=10, gamma=1; total time=  16.1s\n",
      "[CV] END ......................................C=10, gamma=1; total time=  16.0s\n",
      "[CV] END ......................................C=10, gamma=1; total time=  15.9s\n",
      "[CV] END ....................................C=10, gamma=0.1; total time=  16.7s\n",
      "[CV] END ....................................C=10, gamma=0.1; total time=  18.7s\n",
      "[CV] END ....................................C=10, gamma=0.1; total time=  15.1s\n",
      "[CV] END ....................................C=10, gamma=0.1; total time=  15.5s\n",
      "[CV] END ....................................C=10, gamma=0.1; total time=  18.5s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=  14.8s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=  15.1s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=  14.5s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=  14.5s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=  14.7s\n",
      "[CV] END .....................................C=100, gamma=1; total time=  16.5s\n",
      "[CV] END .....................................C=100, gamma=1; total time=  15.8s\n",
      "[CV] END .....................................C=100, gamma=1; total time=  20.5s\n",
      "[CV] END .....................................C=100, gamma=1; total time=  16.1s\n",
      "[CV] END .....................................C=100, gamma=1; total time=  21.3s\n",
      "[CV] END ...................................C=100, gamma=0.1; total time=  15.9s\n",
      "[CV] END ...................................C=100, gamma=0.1; total time=  15.7s\n",
      "[CV] END ...................................C=100, gamma=0.1; total time=  16.9s\n",
      "[CV] END ...................................C=100, gamma=0.1; total time=  14.8s\n",
      "[CV] END ...................................C=100, gamma=0.1; total time=  20.7s\n",
      "[CV] END ..................................C=100, gamma=0.01; total time=  15.3s\n",
      "[CV] END ..................................C=100, gamma=0.01; total time=  15.1s\n",
      "[CV] END ..................................C=100, gamma=0.01; total time=  15.2s\n",
      "[CV] END ..................................C=100, gamma=0.01; total time=  16.9s\n",
      "[CV] END ..................................C=100, gamma=0.01; total time=  14.8s\n",
      "Mejores parámetros encontrados: {'C': 10, 'gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# Definir el grid de hiperparámetros para el SVM\n",
    "param_grid = {\n",
    "    'C': [1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01]\n",
    "}\n",
    "\n",
    "# Configurar GridSearchCV con SVC (kernel 'rbf')\n",
    "grid = GridSearchCV(SVC(kernel='rbf', random_state=42, class_weight='balanced'),\n",
    "                    param_grid, cv=5, verbose=2)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Mejores parámetros encontrados:\", grid.best_params_)\n",
    "\n",
    "# Usar el mejor modelo para predecir en el conjunto de prueba\n",
    "y_pred = grid.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusión:\n",
      "[[723 377]\n",
      " [471 712]]\n",
      "Accuracy: 0.6285589137100307\n",
      "Precision: 0.6538108356290174\n",
      "Recall: 0.6018596787827557\n",
      "F1-score: 0.6267605633802817\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.66      0.63      1100\n",
      "           1       0.65      0.60      0.63      1183\n",
      "\n",
      "    accuracy                           0.63      2283\n",
      "   macro avg       0.63      0.63      0.63      2283\n",
      "weighted avg       0.63      0.63      0.63      2283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(cm)\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall:\", rec)\n",
    "print(\"F1-score:\", f1)\n",
    "print(\"Reporte de clasificación:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de features en entrenamiento: 14\n",
      "Número de features en test: 14\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Y'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     34\u001b[39m X_test = df_test_clean.values\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Realiza las predicciones usando tu modelo entrenado (en este caso, 'grid')\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m df_test[\u001b[33m'\u001b[39m\u001b[33mAccept\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mgrid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Asegúrate de que la columna 'Accept' sea de tipo entero\u001b[39;00m\n\u001b[32m     40\u001b[39m df_test[\u001b[33m'\u001b[39m\u001b[33mAccept\u001b[39m\u001b[33m'\u001b[39m] = df_test[\u001b[33m'\u001b[39m\u001b[33mAccept\u001b[39m\u001b[33m'\u001b[39m].astype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/CDAW_reto1/LBBYs/venv_svm/lib/python3.13/site-packages/sklearn/model_selection/_search.py:598\u001b[39m, in \u001b[36mBaseSearchCV.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    580\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Call predict on the estimator with the best found parameters.\u001b[39;00m\n\u001b[32m    581\u001b[39m \n\u001b[32m    582\u001b[39m \u001b[33;03mOnly available if ``refit=True`` and the underlying estimator supports\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    595\u001b[39m \u001b[33;03m    the best found parameters.\u001b[39;00m\n\u001b[32m    596\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    597\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m598\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbest_estimator_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/CDAW_reto1/LBBYs/venv_svm/lib/python3.13/site-packages/sklearn/svm/_base.py:822\u001b[39m, in \u001b[36mBaseSVC.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    820\u001b[39m     y = np.argmax(\u001b[38;5;28mself\u001b[39m.decision_function(X), axis=\u001b[32m1\u001b[39m)\n\u001b[32m    821\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m822\u001b[39m     y = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.classes_.take(np.asarray(y, dtype=np.intp))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/CDAW_reto1/LBBYs/venv_svm/lib/python3.13/site-packages/sklearn/svm/_base.py:436\u001b[39m, in \u001b[36mBaseLibSVM.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    420\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    421\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Perform regression on samples in X.\u001b[39;00m\n\u001b[32m    422\u001b[39m \n\u001b[32m    423\u001b[39m \u001b[33;03m    For an one-class model, +1 (inlier) or -1 (outlier) is returned.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    434\u001b[39m \u001b[33;03m        The predicted values.\u001b[39;00m\n\u001b[32m    435\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m436\u001b[39m     X = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_for_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    437\u001b[39m     predict = \u001b[38;5;28mself\u001b[39m._sparse_predict \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dense_predict\n\u001b[32m    438\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m predict(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/CDAW_reto1/LBBYs/venv_svm/lib/python3.13/site-packages/sklearn/svm/_base.py:614\u001b[39m, in \u001b[36mBaseLibSVM._validate_for_predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    611\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    613\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.kernel):\n\u001b[32m--> \u001b[39m\u001b[32m614\u001b[39m     X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    615\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    616\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    617\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    618\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    619\u001b[39m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    621\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sparse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp.issparse(X):\n\u001b[32m    625\u001b[39m     X = sp.csr_matrix(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/CDAW_reto1/LBBYs/venv_svm/lib/python3.13/site-packages/sklearn/utils/validation.py:2944\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2942\u001b[39m         out = X, y\n\u001b[32m   2943\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2944\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2945\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2946\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/CDAW_reto1/LBBYs/venv_svm/lib/python3.13/site-packages/sklearn/utils/validation.py:1055\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1053\u001b[39m         array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1054\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1055\u001b[39m         array = \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1056\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1057\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1058\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.format(array)\n\u001b[32m   1059\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcomplex_warning\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/CDAW_reto1/LBBYs/venv_svm/lib/python3.13/site-packages/sklearn/utils/_array_api.py:839\u001b[39m, in \u001b[36m_asarray_with_order\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    837\u001b[39m     array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    838\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m839\u001b[39m     array = \u001b[43mnumpy\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    842\u001b[39m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[32m    843\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m xp.asarray(array)\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'Y'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# Cargar el dataset de test\n",
    "df_test = pd.read_csv(\"/home/ines/dev/CDAW_reto1/LBBYs/data/raw/test_nolabel.csv\")\n",
    "\n",
    "# --- Preprocesamiento ---\n",
    "# Debes replicar exactamente los pasos que aplicaste al entrenamiento.\n",
    "# 1. Eliminar las columnas irrelevantes (como hiciste en entrenamiento)\n",
    "cols_to_drop = ['id', 'LoanNr_ChkDgt', 'Name', 'ApprovalDate', 'DisbursementDate', 'State']\n",
    "df_test_clean = df_test.drop(columns=cols_to_drop)\n",
    "\n",
    "# 2. Aplicar one-hot encoding a las columnas categóricas que usaste en entrenamiento:\n",
    "#    En tu entrenamiento usaste: ['Bank', 'City', 'BankState'] con drop_first=True.\n",
    "df_test_clean = pd.get_dummies(df_test_clean, columns=['Bank', 'City', 'BankState'], drop_first=True)\n",
    "\n",
    "# 3. Imputar valores nulos (igual que en entrenamiento)\n",
    "df_test_clean.fillna(0, inplace=True)\n",
    "\n",
    "# --- Alinear las features ---\n",
    "# Durante el entrenamiento, tu DataFrame final balanceado 'df_clean' tenía un cierto conjunto de columnas (features).\n",
    "# Asumiendo que entrenaste el modelo con:\n",
    "#   X_train = df_clean.drop('Accept', axis=1)\n",
    "# Guarda la lista de features de entrenamiento:\n",
    "features = list(df_balanced.drop('Accept', axis=1).columns)\n",
    "print(\"Número de features en entrenamiento:\", len(features))\n",
    "\n",
    "# Reindexa el DataFrame de test para que tenga exactamente las mismas columnas, llenando con 0 las que no estén.\n",
    "df_test_clean = df_test_clean.reindex(columns=features, fill_value=0)\n",
    "print(\"Número de features en test:\", df_test_clean.shape[1])\n",
    "\n",
    "# --- Predicción ---\n",
    "# Extrae el array de features del test\n",
    "X_test = df_test_clean.values\n",
    "\n",
    "# Realiza las predicciones usando tu modelo entrenado (en este caso, 'grid')\n",
    "df_test['Accept'] = grid.predict(X_test)\n",
    "\n",
    "# Asegúrate de que la columna 'Accept' sea de tipo entero\n",
    "df_test['Accept'] = df_test['Accept'].astype(int)\n",
    "\n",
    "# --- Exportar Submission ---\n",
    "# Crea el archivo CSV con las columnas requeridas: 'id' y 'Accept'\n",
    "filename = f\"svm_update_{datetime.datetime.now().strftime('%Y%m%d_%H_%M_%S')}.csv\"\n",
    "df_test.to_csv(filename, columns=['id', 'Accept'], index=False)\n",
    "\n",
    "print(\"Archivo de submission 'my-model.csv' generado correctamente.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_svm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
