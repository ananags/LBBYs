{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesado dataset\n",
    "\n",
    "Procesado del dataset en base al análisis previo. Este procesado sirve tanto para el conjunto de entrenamiento como para los conjuntos que se quieran clasisificar con los modelos. Haciendo este procesado común nos aseguramos que los datos que manejan los modelos tienen los mismos formatos y cualidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external imports\n",
    "import os\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "data_folder=\"../../data\"\n",
    "raw_data_folder = f\"{data_folder}/raw\"\n",
    "processed_data_folder = f\"{data_folder}/processed\"\n",
    "\n",
    "original_train_dataset_path = f\"{raw_data_folder}/train.csv\"\n",
    "original_test_dataset_path = f\"{raw_data_folder}/test_nolabel.csv\"\n",
    "\n",
    "train_dataset_processed_path = f\"{processed_data_folder}/train_processed.csv\"\n",
    "train_dataset_balanced_processed_path = f\"{processed_data_folder}/train_balanced_processed.csv\"\n",
    "test_nolabel_processed_path = f\"{processed_data_folder}/test_nolabel_processed.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>LoanNr_ChkDgt</th>\n",
       "      <th>Name</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Bank</th>\n",
       "      <th>BankState</th>\n",
       "      <th>ApprovalDate</th>\n",
       "      <th>ApprovalFY</th>\n",
       "      <th>NoEmp</th>\n",
       "      <th>...</th>\n",
       "      <th>CreateJob</th>\n",
       "      <th>RetainedJob</th>\n",
       "      <th>FranchiseCode</th>\n",
       "      <th>UrbanRural</th>\n",
       "      <th>RevLineCr</th>\n",
       "      <th>LowDoc</th>\n",
       "      <th>DisbursementDate</th>\n",
       "      <th>DisbursementGross</th>\n",
       "      <th>BalanceGross</th>\n",
       "      <th>Accept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bd9d6267ec5</td>\n",
       "      <td>1523195006</td>\n",
       "      <td>P-SCAPE LAND DESIGN, LLC</td>\n",
       "      <td>NORTHFIELD</td>\n",
       "      <td>OH</td>\n",
       "      <td>CITIZENS BANK NATL ASSOC</td>\n",
       "      <td>RI</td>\n",
       "      <td>1-Nov-05</td>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>31-Dec-05</td>\n",
       "      <td>$8,000.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9eebf6d8098</td>\n",
       "      <td>1326365010</td>\n",
       "      <td>The Fresh &amp; Healthy Catering C</td>\n",
       "      <td>CANTON</td>\n",
       "      <td>OH</td>\n",
       "      <td>FIRSTMERIT BANK, N.A.</td>\n",
       "      <td>OH</td>\n",
       "      <td>6-Jun-05</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>31-Jul-05</td>\n",
       "      <td>$166,000.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83806858500</td>\n",
       "      <td>6179584001</td>\n",
       "      <td>AARON MASON &amp; HOWE LLC</td>\n",
       "      <td>SAWYERWOOD</td>\n",
       "      <td>OH</td>\n",
       "      <td>PNC BANK, NATIONAL ASSOCIATION</td>\n",
       "      <td>OH</td>\n",
       "      <td>18-Mar-03</td>\n",
       "      <td>2003</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>31-Mar-03</td>\n",
       "      <td>$25,000.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a21ab9cb3af</td>\n",
       "      <td>8463493009</td>\n",
       "      <td>MID OHIO CAR WASH</td>\n",
       "      <td>COLUMBUS</td>\n",
       "      <td>OH</td>\n",
       "      <td>THE HUNTINGTON NATIONAL BANK</td>\n",
       "      <td>OH</td>\n",
       "      <td>28-Jun-95</td>\n",
       "      <td>1995</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>31-Jan-96</td>\n",
       "      <td>$220,100.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>883b5e5385e</td>\n",
       "      <td>3382225007</td>\n",
       "      <td>Bake N Brew LLC</td>\n",
       "      <td>Newark</td>\n",
       "      <td>OH</td>\n",
       "      <td>THE HUNTINGTON NATIONAL BANK</td>\n",
       "      <td>OH</td>\n",
       "      <td>16-Apr-09</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>31-May-09</td>\n",
       "      <td>$25,000.00</td>\n",
       "      <td>$0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  LoanNr_ChkDgt                            Name        City  \\\n",
       "0  bd9d6267ec5     1523195006        P-SCAPE LAND DESIGN, LLC  NORTHFIELD   \n",
       "1  9eebf6d8098     1326365010  The Fresh & Healthy Catering C      CANTON   \n",
       "2  83806858500     6179584001          AARON MASON & HOWE LLC  SAWYERWOOD   \n",
       "3  a21ab9cb3af     8463493009               MID OHIO CAR WASH    COLUMBUS   \n",
       "4  883b5e5385e     3382225007                 Bake N Brew LLC      Newark   \n",
       "\n",
       "  State                            Bank BankState ApprovalDate  ApprovalFY  \\\n",
       "0    OH        CITIZENS BANK NATL ASSOC        RI     1-Nov-05        2006   \n",
       "1    OH           FIRSTMERIT BANK, N.A.        OH     6-Jun-05        2005   \n",
       "2    OH  PNC BANK, NATIONAL ASSOCIATION        OH    18-Mar-03        2003   \n",
       "3    OH    THE HUNTINGTON NATIONAL BANK        OH    28-Jun-95        1995   \n",
       "4    OH    THE HUNTINGTON NATIONAL BANK        OH    16-Apr-09        2009   \n",
       "\n",
       "   NoEmp  ...  CreateJob  RetainedJob  FranchiseCode  UrbanRural  RevLineCr  \\\n",
       "0      2  ...          0            2              0           1          N   \n",
       "1      2  ...          1            2              1           1          N   \n",
       "2      2  ...          4            2              1           2          Y   \n",
       "3      2  ...          0            0              1           0          N   \n",
       "4      0  ...          0            0              0           1          N   \n",
       "\n",
       "  LowDoc DisbursementDate DisbursementGross BalanceGross Accept  \n",
       "0      N        31-Dec-05        $8,000.00        $0.00       1  \n",
       "1      N        31-Jul-05      $166,000.00        $0.00       1  \n",
       "2      N        31-Mar-03       $25,000.00        $0.00       1  \n",
       "3      N        31-Jan-96      $220,100.00        $0.00       1  \n",
       "4      N        31-May-09       $25,000.00        $0.00       0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload the dataset\n",
    "original_train_df = pd.read_csv(original_train_dataset_path, sep=\",\")\n",
    "original_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesado por columnas\n",
    "\n",
    "En la siguiente sección aplicamos el procesamiemto de datos a cada columna adecuado. Un tratamiento común será rellenar todos los valores nulos de manera que los datasets sobre los que se realicen las predicciones no tengan nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22835 entries, 0 to 22834\n",
      "Data columns (total 21 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 22835 non-null  object \n",
      " 1   LoanNr_ChkDgt      22835 non-null  int64  \n",
      " 2   Name               22834 non-null  object \n",
      " 3   City               22834 non-null  object \n",
      " 4   State              22835 non-null  object \n",
      " 5   Bank               22813 non-null  object \n",
      " 6   BankState          22813 non-null  object \n",
      " 7   ApprovalDate       22835 non-null  object \n",
      " 8   ApprovalFY         22835 non-null  int64  \n",
      " 9   NoEmp              22835 non-null  int64  \n",
      " 10  NewExist           22833 non-null  float64\n",
      " 11  CreateJob          22835 non-null  int64  \n",
      " 12  RetainedJob        22835 non-null  int64  \n",
      " 13  FranchiseCode      22835 non-null  int64  \n",
      " 14  UrbanRural         22835 non-null  int64  \n",
      " 15  RevLineCr          22744 non-null  object \n",
      " 16  LowDoc             22792 non-null  object \n",
      " 17  DisbursementDate   22774 non-null  object \n",
      " 18  DisbursementGross  22835 non-null  object \n",
      " 19  BalanceGross       22835 non-null  object \n",
      " 20  Accept             22835 non-null  int64  \n",
      "dtypes: float64(1), int64(8), object(12)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "processed_train_df = original_train_df.copy()\n",
    "processed_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accept\n",
       "1    19004\n",
       "0     3831\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_train_df[\"Accept\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3284 entries, 0 to 3283\n",
      "Data columns (total 20 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 3284 non-null   object \n",
      " 1   LoanNr_ChkDgt      3284 non-null   int64  \n",
      " 2   Name               3284 non-null   object \n",
      " 3   City               3284 non-null   object \n",
      " 4   State              3284 non-null   object \n",
      " 5   Bank               3279 non-null   object \n",
      " 6   BankState          3279 non-null   object \n",
      " 7   ApprovalDate       3284 non-null   object \n",
      " 8   ApprovalFY         3284 non-null   object \n",
      " 9   NoEmp              3284 non-null   int64  \n",
      " 10  NewExist           3284 non-null   float64\n",
      " 11  CreateJob          3284 non-null   int64  \n",
      " 12  RetainedJob        3284 non-null   int64  \n",
      " 13  FranchiseCode      3284 non-null   int64  \n",
      " 14  UrbanRural         3284 non-null   int64  \n",
      " 15  RevLineCr          3280 non-null   object \n",
      " 16  LowDoc             3275 non-null   object \n",
      " 17  DisbursementDate   3277 non-null   object \n",
      " 18  DisbursementGross  3284 non-null   object \n",
      " 19  BalanceGross       3284 non-null   object \n",
      "dtypes: float64(1), int64(6), object(13)\n",
      "memory usage: 513.3+ KB\n"
     ]
    }
   ],
   "source": [
    "test_nolabel_processed_df = pd.read_csv(original_test_dataset_path, sep=\",\")\n",
    "test_nolabel_processed_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_column_id(df: pd.DataFrame): \n",
    "    # Procesado de columna\n",
    "    column = \"id\"\n",
    "\n",
    "    # No interesa para el modelo\n",
    "    df.drop(columns=column, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_column_LoanNr_ChkDgt(df: pd.DataFrame): \n",
    "    # Procesado de columna\n",
    "    column = \"LoanNr_ChkDgt\"\n",
    "\n",
    "    # No interesa para el modelo\n",
    "    df.drop(columns=column, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_column_Name(df: pd.DataFrame): \n",
    "    # Procesado de columna\n",
    "    column = \"Name\"\n",
    "\n",
    "    # No interesa para el modelo\n",
    "    df.drop(columns=column, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_column_City(df: pd.DataFrame): \n",
    "    # Procesado de columna\n",
    "    column = \"City\"\n",
    "\n",
    "    # No interesa para el modelo\n",
    "    df.drop(columns=column, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_column_State(df: pd.DataFrame): \n",
    "    # Procesado de columna\n",
    "    column = \"State\"\n",
    "\n",
    "    # No interesa para el modelo\n",
    "    df.drop(columns=column, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_column_Bank(df: pd.DataFrame): \n",
    "    # Procesado de columna\n",
    "    column = \"Bank\"\n",
    "\n",
    "    # No interesa para el modelo\n",
    "    df.drop(columns=column, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_column_BankState(df: pd.DataFrame): \n",
    "    # Procesado de columna\n",
    "    column = \"BankState\"\n",
    "    column_grouped = \"BankStateInOhio\"\n",
    "\n",
    "    # Cambio de valores a binario\n",
    "    df[column] = df[column].fillna(\"OH\")\n",
    "    df.loc[\n",
    "        df[column] == \"OH\",\n",
    "        column_grouped\n",
    "    ] = int(1)\n",
    "\n",
    "    df.loc[\n",
    "        df[column] != \"OH\",\n",
    "        column_grouped\n",
    "    ] = int(0)\n",
    "\n",
    "    df.drop(columns=column, inplace=True)\n",
    "\n",
    "    df[column_grouped] = df[column_grouped].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_column_ApprovalDate(df: pd.DataFrame): \n",
    "    # Procesado de columna\n",
    "    column = \"ApprovalDate\"\n",
    "\n",
    "    # Al ser una fecha se dividirá en 2 columnas, una para el mes y otra para el año\n",
    "    df[column] = pd.to_datetime(df[column])\n",
    "\n",
    "    df[\"ApprovalDateMonth\"] = df[column].dt.month\n",
    "    df[\"ApprovalDateMonth\"] = df[\"ApprovalDateMonth\"].astype(\"int64\")\n",
    "\n",
    "    # Elimino la columna que ya no sirve\n",
    "    df.drop(columns=column, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_column_ApprovalFY(df: pd.DataFrame): \n",
    "    # Procesado de columna\n",
    "    column = \"ApprovalFY\"\n",
    "    column_grouped = f\"{column}Grouped\"\n",
    "\n",
    "    df[column] = df[column].astype(str).str.replace(r\"\\D\", \"\", regex=True)\n",
    "    # Cambio a enteros\n",
    "    df[column] = df[column].astype(\"int64\") \n",
    "\n",
    "    fiscal_year_mode = df[column].mode()[0]\n",
    "\n",
    "    # Agrupación de años\n",
    "    def agrupar_años(year:int):\n",
    "        if 1970 <= year < 1980:\n",
    "            return 1975\n",
    "        elif 1980 <= year < 1990:\n",
    "            return 1989\n",
    "        elif year > 2025:\n",
    "            return fiscal_year_mode\n",
    "        else:\n",
    "            return year\n",
    "\n",
    "    # Agrupo\n",
    "    df[column_grouped] = df[column].apply(agrupar_años)\n",
    "    # Camnbio a enteros\n",
    "    df[column_grouped] = df[column_grouped].astype(\"int64\")\n",
    "    # Elimino la columna que ya no sirve\n",
    "    df.drop(columns=column, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_column_NoEmp(df: pd.DataFrame): \n",
    "    # Procesado de columna\n",
    "    column = \"NoEmp\"\n",
    "    column_grouped = f\"{column}Grouped\"\n",
    "\n",
    "    # Agrupación de años\n",
    "    def agrupar_numero_empleado(value:int):\n",
    "        if value <= 10:\n",
    "            return 0\n",
    "        return 1\n",
    "        \n",
    "    df[column_grouped] = df[column].apply(agrupar_numero_empleado)\n",
    "    # Camnbio a enteros\n",
    "    df[column_grouped] = df[column_grouped].astype(\"int64\")\n",
    "    # Elimino la columna que ya no sirve\n",
    "    df.drop(columns=column, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_column_NewExist(df: pd.DataFrame): \n",
    "    # Procesado de columna\n",
    "    column = \"NewExist\"\n",
    "\n",
    "    # Sustituyo nulos\n",
    "    df[column] = df[column].fillna(df[column].mode()[0])\n",
    "    # Camnbio a enteros\n",
    "    df[column] = df[column].astype(\"int64\")\n",
    "\n",
    "    df.loc[\n",
    "        df[column] != 2,\n",
    "        column\n",
    "    ] = int(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_column_CreateJob(df: pd.DataFrame): \n",
    "    # Procesado de columna\n",
    "    column = \"CreateJob\"\n",
    "    column_grouped = \"CreateJobBinary\"\n",
    "\n",
    "    # Sustituyo nulos\n",
    "    df[column] = df[column].fillna(df[column].mode()[0])\n",
    "    # Cambio a enteros\n",
    "    df[column] = df[column].astype(\"int64\")\n",
    "\n",
    "    df[column_grouped] = 0\n",
    "    df.loc[\n",
    "        df[column] > 0,\n",
    "        column_grouped\n",
    "    ] = int(1)\n",
    "\n",
    "    # Elimino la columna que ya no sirve\n",
    "    df.drop(columns=column, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_column_RetainedJob(df: pd.DataFrame): \n",
    "    # Procesado de columna\n",
    "    column = \"RetainedJob\"\n",
    "    column_grouped = \"RetainedJobBinary\"\n",
    "\n",
    "    # Sustituyo nulos\n",
    "    df[column] = df[column].fillna(df[column].mode()[0])\n",
    "    # Cambio a enteros\n",
    "    df[column] = df[column].astype(\"int64\")\n",
    "\n",
    "    df[column_grouped] = 0\n",
    "    df.loc[\n",
    "        df[column] > 0,\n",
    "        column_grouped\n",
    "    ] = int(1)\n",
    "\n",
    "    # Elimino la columna que ya no sirve\n",
    "    df.drop(columns=column, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_column_FranchiseCode(df: pd.DataFrame): \n",
    "    # Procesado de columna\n",
    "    column = \"FranchiseCode\"\n",
    "    column_grouped = \"IsFranchise\"\n",
    "\n",
    "    # Sustituyo nulos\n",
    "    df[column] = df[column].fillna(df[column].mode()[0])\n",
    "    # Cambio a enteros\n",
    "    df[column] = df[column].astype(\"int64\")\n",
    "\n",
    "    df[column_grouped] = 0\n",
    "    df.loc[\n",
    "        (df[column] != 0) &\n",
    "        (df[column] != 1),\n",
    "        column_grouped\n",
    "    ] = int(1)\n",
    "\n",
    "\n",
    "    # Elimino la columna que ya no sirve\n",
    "    df.drop(columns=column, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_column_UrbanRural(df: pd.DataFrame):     \n",
    "    # Procesado de columna\n",
    "    column = \"UrbanRural\"\n",
    "\n",
    "    # Sustituyo nulos\n",
    "    df[column] = df[column].fillna(df[column].mode()[0])\n",
    "    # Camnbio a enteros\n",
    "    df[column] = df[column].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_column_RevLineCr(df: pd.DataFrame): \n",
    "    # Procesado de columna\n",
    "    column = \"RevLineCr\"\n",
    "\n",
    "    # Sustituyo nulos\n",
    "    df[column] = df[column].fillna(df[column].mode()[0])\n",
    "\n",
    "    # Modifico valores extraños\n",
    "    df.loc[\n",
    "        df[column] == \"N\",\n",
    "        column\n",
    "    ] = int(0)\n",
    "\n",
    "    df.loc[\n",
    "        (df[column] == \"Y\") |\n",
    "        (df[column] == \"T\"),\n",
    "        column\n",
    "    ] = int(1)\n",
    "\n",
    "    df.loc[\n",
    "        (df[column] != 1) &\n",
    "        (df[column] != 0),\n",
    "        column\n",
    "    ] = int(0)\n",
    "\n",
    "    # Cambio a enteros\n",
    "    df[column] = df[column].astype(\"int64\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_column_LowDoc(df: pd.DataFrame): \n",
    "    # Procesado de columna\n",
    "    column = \"LowDoc\"\n",
    "\n",
    "    # Sustituyo nulos\n",
    "    df[column] = df[column].fillna(df[column].mode()[0])\n",
    "\n",
    "    # Modifico valores extraños\n",
    "    df.loc[\n",
    "        df[column] == \"Y\",\n",
    "        column\n",
    "    ] = int(1)\n",
    "\n",
    "    df.loc[\n",
    "        (df[column] != 1),\n",
    "        column\n",
    "    ] = int(0)\n",
    "\n",
    "    # Cambio a enteros\n",
    "    df[column] = df[column].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_column_DisbursementDate(df: pd.DataFrame):     \n",
    "    # Procesado de columna\n",
    "    column = \"DisbursementDate\"\n",
    "\n",
    "    # Elimino la columna que ya no sirve\n",
    "    df.drop(columns=column, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:11: SyntaxWarning: invalid escape sequence '\\$'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\$'\n",
      "/tmp/ipykernel_2415616/3769527384.py:11: SyntaxWarning: invalid escape sequence '\\$'\n",
      "  df[column] = df[column].replace('[\\$,]', '', regex=True).astype(float)\n"
     ]
    }
   ],
   "source": [
    "def process_column_DisbursementGross(df: pd.DataFrame): \n",
    "    # Procesado de columna\n",
    "    column = \"DisbursementGross\"\n",
    "    column_grouped = \"DisbursementGrossGrouped\"\n",
    "\n",
    "\n",
    "    # Sustituyo nulos\n",
    "    df[column] = df[column].fillna(df[column].mode()[0])\n",
    "\n",
    "    # Para convertir la moneda en un número\n",
    "    df[column] = df[column].replace('[\\$,]', '', regex=True).astype(float)\n",
    "\n",
    "    # Agrupación de años\n",
    "    def agrupar_gross(value:int):\n",
    "        if value <= 50000:\n",
    "            return 0\n",
    "        elif 50000 < value <= 250000:\n",
    "            return 1\n",
    "        elif 250000 < value <= 1000000:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "\n",
    "    df[column_grouped] = df[column].apply(agrupar_gross)\n",
    "\n",
    "    # Cambio a enteros\n",
    "    df[column_grouped] = df[column_grouped].astype(\"int64\")\n",
    "\n",
    "    # Elimino la columna que ya no sirve\n",
    "    df.drop(columns=column, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_column_BalanceGross(df: pd.DataFrame): \n",
    "    # Procesado de columna\n",
    "    column = \"BalanceGross\"\n",
    "\n",
    "    # Elimino la columna que ya no sirve\n",
    "    df.drop(columns=column, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dataset_process(dataframe: pd.DataFrame):\n",
    "    process_column_LoanNr_ChkDgt(dataframe)\n",
    "    process_column_Name(dataframe)\n",
    "    process_column_City(dataframe)\n",
    "    process_column_State(dataframe)\n",
    "    process_column_Bank(dataframe)\n",
    "    process_column_BankState(dataframe)\n",
    "    process_column_ApprovalDate(dataframe)\n",
    "    process_column_ApprovalFY(dataframe)\n",
    "    process_column_NoEmp(dataframe)\n",
    "    process_column_NewExist(dataframe)\n",
    "    process_column_CreateJob(dataframe)\n",
    "    process_column_RetainedJob(dataframe)\n",
    "    process_column_FranchiseCode(dataframe)\n",
    "    process_column_UrbanRural(dataframe)\n",
    "    process_column_RevLineCr(dataframe)\n",
    "    process_column_LowDoc(dataframe)\n",
    "    process_column_DisbursementDate(dataframe)\n",
    "    process_column_DisbursementGross(dataframe)\n",
    "    process_column_BalanceGross(dataframe)\n",
    "\n",
    "def dataset_process(dataframe: pd.DataFrame):\n",
    "    process_column_id(dataframe)\n",
    "    test_dataset_process(dataframe)\n",
    "    dataframe.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2415616/3003256540.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column])\n",
      "/tmp/ipykernel_2415616/3003256540.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[column] = pd.to_datetime(df[column])\n"
     ]
    }
   ],
   "source": [
    "test_dataset_process(test_nolabel_processed_df)\n",
    "dataset_process(processed_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardamos el dataset procesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 14434 entries, 0 to 22829\n",
      "Data columns (total 13 columns):\n",
      " #   Column                    Non-Null Count  Dtype\n",
      "---  ------                    --------------  -----\n",
      " 0   NewExist                  14434 non-null  int64\n",
      " 1   UrbanRural                14434 non-null  int64\n",
      " 2   RevLineCr                 14434 non-null  int64\n",
      " 3   LowDoc                    14434 non-null  int64\n",
      " 4   Accept                    14434 non-null  int64\n",
      " 5   BankStateInOhio           14434 non-null  int64\n",
      " 6   ApprovalDateMonth         14434 non-null  int64\n",
      " 7   ApprovalFYGrouped         14434 non-null  int64\n",
      " 8   NoEmpGrouped              14434 non-null  int64\n",
      " 9   CreateJobBinary           14434 non-null  int64\n",
      " 10  RetainedJobBinary         14434 non-null  int64\n",
      " 11  IsFranchise               14434 non-null  int64\n",
      " 12  DisbursementGrossGrouped  14434 non-null  int64\n",
      "dtypes: int64(13)\n",
      "memory usage: 1.5 MB\n"
     ]
    }
   ],
   "source": [
    "processed_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accept\n",
       "1    11508\n",
       "0     2926\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_train_df[\"Accept\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que el dataset está desbalanceado crearemos uno que este balanceado, en este caso eliminando casos del lado desbalanceado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_balanced_df = processed_train_df.copy()\n",
    "\n",
    "counts = processed_train_balanced_df[\"Accept\"].value_counts()\n",
    "\n",
    "# Número de filas que hay que eliminar\n",
    "n_to_remove = counts[1] - counts[0]\n",
    "\n",
    "# Borrado aleatorio\n",
    "processed_train_balanced_df = processed_train_balanced_df.drop(\n",
    "    processed_train_balanced_df[processed_train_balanced_df[\"Accept\"] == 1].sample(n=n_to_remove, random_state=42).index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_df.to_csv(train_dataset_processed_path, sep=\",\", index=False)\n",
    "processed_train_balanced_df.to_csv(train_dataset_balanced_processed_path, sep=\",\", index=False)\n",
    "test_nolabel_processed_df.to_csv(test_nolabel_processed_path, sep=\",\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_svm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
